{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0b782f",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"100\" height=\"100\" src=\"../images/logo.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b8820",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1>03. Preproceso: Modelo C_SEV</h1> \n",
    "\n",
    "Canadian Car Accidents Practice <br>\n",
    "<strong>Aprendizaje Automático</strong> <br>\n",
    "<strong>Master Universitario en Ciencia de Datos<strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f538c4",
   "metadata": {},
   "source": [
    "<div style='text-align:right'>Álvaro Serrano del Rincón (<i>a.serranodelrincon@cunef.edu</i>)</div>\n",
    "<div style='text-align:right'>Carlos Viñals Guitart (<i>carlos.vinals@cunef.edu</i>)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddd49a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde5d6b",
   "metadata": {},
   "source": [
    "## 3.0 Introducción\n",
    "\n",
    "En este notebook realizaremos el preprocesado de los datos del dataset conforme al análisis realizado en el notebook EDA \n",
    "```01_EDA```. Para ello procederemos a explicar paso a paso las decisiones tomadas en cuanto a su preprocesado.\n",
    "\n",
    "Para este trabajo estamos utilizando un entorno de propósito espécifico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e740ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos el entorno: ML_P1\n",
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb9541",
   "metadata": {},
   "source": [
    "### 3.0.1 Estructura\n",
    "\n",
    "<< PONER ESTRUCTURA >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37289651",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a24d6",
   "metadata": {},
   "source": [
    "## Scripts\n",
    "En este notebook procedemos a importar dos scripts con funciones útiles, previamente utilizadas en el EDA y que permitirán verificar el proceso de realización de las muestras de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e89e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '../scripts/')\n",
    "\n",
    "import csv_tools\n",
    "import eda_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be658ea",
   "metadata": {},
   "source": [
    "## 3.1 Lectura y preparación\n",
    "\n",
    "A continuación leeremos el dataset, de la misma forma que lo hicimos en el EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función propia que verifica que existe el fichero de datos previamente.\n",
    "accidents_df = csv_tools.csv_import(origin=\"../data/sev_df_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dffbcd",
   "metadata": {},
   "source": [
    "## 3.2 Train y Test\n",
    "A continuación vamos a proceder a crear y dividir los datos en Train (muestra de entrenamiento) y test (muestra de test) que usaremos para nuestros modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los valores (X) de la variable objetivo (Y)\n",
    "X = accidents_df.drop('C_SEV', axis=1)\n",
    "Y = accidents_df['C_SEV']\n",
    "\n",
    "# Realizamos la división de train y test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=1234, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260895e",
   "metadata": {},
   "source": [
    "## 3.3 Tratamiento\n",
    "A continuación procederemos a realizar la limpieza de los datos y su procesamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422337b",
   "metadata": {},
   "source": [
    "Analizamos tipos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_tools.dataset_overview(data = X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3f7b5a",
   "metadata": {},
   "source": [
    "### 3.4.2 Valores faltantes\n",
    "Para llevar a cabo este proceso realizaremos la conversión correspondiente por tipo de variable, esto es, pues el signficado que estas tienen es distinto. \n",
    "\n",
    "A nivel general si el porcentaje es inferior a 0.1 dedicidimos eliminar esas variables, en caso contrario aplicaremos una técnicas de sustitución de ese valor. Consideramos que un valor inferior a 0.1 no es relevante para los datos.\n",
    "\n",
    "Primero veamos como está la muestra de train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "especial_values = [['U', 'UU', 'UUUU'], ['Q', 'QQ', 'QQQQ']]\n",
    "\n",
    "# Valoración del train\n",
    "eda_tools.special_values_summary(df = X_train, vals = especial_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e55e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valoración del test\n",
    "eda_tools.special_values_summary(df = X_test, vals = especial_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27009912",
   "metadata": {},
   "source": [
    "Generalmente analizaremos primero el porcentaje de valores especiales, siendo igual o inferior a 0.1% el criterio de eliminación de estos del dataset. En el resto se analizará la variable objetivo mayoritaria y se buscará el valor más frecuente con la misma variable objetivo para realizar la clasificación. En el caso de las variables ```Q``` se seguirá el mismo criterio si bien en algunos casos por razones de que no se tratan de simples datos faltantes deberán categorizarse de manera específica.\n",
    "Lo analizamos a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f505e0",
   "metadata": {},
   "source": [
    "```C_MNTH```: Observamos valores ```U```, estos son inferiores a un 0.1% lo que los hace insignificantes dentro y por lo tanto los eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbe33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "to_drop = X_train[X_train['C_MNTH'] == 'UU'].index\n",
    "X_train = X_train.drop(to_drop, axis=0)\n",
    "Y_train = Y_train.drop(to_drop, axis=0)\n",
    "\n",
    "# Test\n",
    "to_drop = X_test[X_test['C_MNTH'] == 'UU'].index\n",
    "X_test = X_test.drop(to_drop, axis=0)\n",
    "Y_test = Y_test.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d356ee5",
   "metadata": {},
   "source": [
    "```C_WDAY```: Observamos valores ```U```, estos son inferiores a un 0.1% lo que los hace insignificantes dentro y por lo tanto los eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "to_drop = X_train[X_train['C_WDAY'] == 'U'].index\n",
    "X_train = X_train.drop(to_drop, axis=0)\n",
    "Y_train = Y_train.drop(to_drop, axis=0)\n",
    "\n",
    "# Test\n",
    "to_drop = X_test[X_test['C_WDAY'] == 'U'].index\n",
    "X_test = X_test.drop(to_drop, axis=0)\n",
    "Y_test = Y_test.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1118bd",
   "metadata": {},
   "source": [
    "```C_HOUR```: Observamos que hay valores ```U```. Hacemos uso de una tabla resumen que muestra el porcentaje de valores por categoría y la variable objetivo mayoritaria de esa categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_HOUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7fbcf",
   "metadata": {},
   "source": [
    "Categorizaremos los valores ```UU``` como accidentes nocturnos (```night```), pues es la variable mayoritaria con su misma variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a64ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['C_HOUR'] = X_train['C_HOUR'].replace(to_replace = 'UU', value = 'night')\n",
    "X_test['C_HOUR'] = X_test['C_HOUR'].replace(to_replace = 'UU', value = 'night')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce10dd",
   "metadata": {},
   "source": [
    "```C_VEHS```: Observamos valores ```U```, estos son inferiores a un 0.1% lo que los hace insignificantes dentro y por lo tanto los eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "to_drop = X_train[X_train['C_VEHS'] == 'UU'].index\n",
    "X_train = X_train.drop(to_drop, axis=0)\n",
    "Y_train = Y_train.drop(to_drop, axis=0)\n",
    "\n",
    "# Test\n",
    "to_drop = X_test[X_test['C_VEHS'] == 'UU'].index\n",
    "X_test = X_test.drop(to_drop, axis=0)\n",
    "Y_test = Y_test.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806da87",
   "metadata": {},
   "source": [
    "```C_CONF```: Tiene valores ```U``` y ```Q```. Ambos valores presentan la misma variable objetivo mayoritaria respecto a una de las clases, por lo que las clasificaremos como ```one vehicle```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d272809",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_CONF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores QQ se engloban dentro de la categoría other\n",
    "X_train['C_CONF'] = X_train['C_CONF'].replace(to_replace = 'QQ', value = 'one vehicle')\n",
    "X_test['C_CONF'] = X_test['C_CONF'].replace(to_replace = 'QQ', value = 'one vehicle')\n",
    "\n",
    "# Valores UU se traspasan a la categoría de back\n",
    "X_train['C_CONF'] = X_train['C_CONF'].replace(to_replace = 'UU', value = 'one vehicle')\n",
    "X_test['C_CONF'] = X_test['C_CONF'].replace(to_replace = 'UU', value = 'one vehicle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466ad16",
   "metadata": {},
   "source": [
    "```C_RCFG```: Tiene valores ```U``` y ```Q```. Los valores ```Q``` por su naturaleza se asignan a la categoría ```specific```, los valores ```U``` se categorizarán como ```normal```, pues coincide en variable objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_RCFG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores QQ se engloban dentro de la categoría specific, no pueden ser normales\n",
    "X_train['C_RCFG'] = X_train['C_RCFG'].replace(to_replace = 'QQ', value = 'specific')\n",
    "X_test['C_RCFG'] = X_test['C_RCFG'].replace(to_replace = 'QQ', value = 'specific')\n",
    "\n",
    "# Valores UU se traspasan a la categoría de specific, misma C_SEV\n",
    "X_train['C_RCFG'] = X_train['C_RCFG'].replace(to_replace = 'UU', value = 'normal')\n",
    "X_test['C_RCFG'] = X_test['C_RCFG'].replace(to_replace = 'UU', value = 'normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f96a2",
   "metadata": {},
   "source": [
    "```C_WTHR```: Tiene valores ```U``` y ```Q```. Los valores ```Q``` por su naturaleza se asignan a la categoría ```bad```, asumimos que son condiciones poco habituales. En el caso de los valores ```U``` se caracterizan como ```normal``` al coincidir su variabe objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_WTHR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores QQ se engloban dentro de la categoría bad, asumimos que son condiciones poco habituales\n",
    "X_train['C_WTHR'] = X_train['C_WTHR'].replace(to_replace = 'Q', value = 'bad')\n",
    "X_test['C_WTHR'] = X_test['C_WTHR'].replace(to_replace = 'Q', value = 'bad')\n",
    "\n",
    "# Valores UU se traspasan a la categoría de normal, variable mayoritaria (sin coincidencias de CSEV)\n",
    "X_train['C_WTHR'] = X_train['C_WTHR'].replace(to_replace = 'U', value = 'normal')\n",
    "X_test['C_WTHR'] = X_test['C_WTHR'].replace(to_replace = 'U', value = 'normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccf6fe",
   "metadata": {},
   "source": [
    "```C_RSUR```: Tiene valores ```U``` y ```Q```. Los cuales cuales clasificaremos como carreteras con problemas (```dragged```). Pues ambas poseen una variable objetivo mayoritaria común y, además, las ```Q``` por su razón de ser otro tipo de situación de carretera no contemplada la debemos de clasificar en esta segunda categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_RSUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d620ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores Q se engloban dentro de la categoría dragged, no pueden ser normales\n",
    "X_train['C_RSUR'] = X_train['C_RSUR'].replace(to_replace = 'Q', value = 'dragged')\n",
    "X_test['C_RSUR'] = X_test['C_RSUR'].replace(to_replace = 'Q', value = 'dragged')\n",
    "\n",
    "# Valores U se traspasan a la categoría de dragged, misma C_SEV\n",
    "X_train['C_RSUR'] = X_train['C_RSUR'].replace(to_replace = 'U', value = 'dragged')\n",
    "X_test['C_RSUR'] = X_test['C_RSUR'].replace(to_replace = 'U', value = 'dragged')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c772e",
   "metadata": {},
   "source": [
    "```C_RALN```: Observamos variables ```U``` y ```Q```. Las ```Q``` se clasifican como otros tipos de carreteras: ```curve/ramp```, pues no pueden ser de la otra categoría. En el caso de ```U```, siguiendo la mayoría de la variable objetivo se clasifica como ```normal```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_RALN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores Q se engloban dentro de la categoría curve/ramp, no pueden ser normales\n",
    "X_train['C_RALN'] = X_train['C_RALN'].replace(to_replace = 'Q', value = 'curve/ramp')\n",
    "X_test['C_RALN'] = X_test['C_RALN'].replace(to_replace = 'Q', value = 'curve/ramp')\n",
    "\n",
    "# Valores U se traspasan a la categoría normal, misma C_SEV\n",
    "X_train['C_RALN'] = X_train['C_RALN'].replace(to_replace = 'U', value = 'normal')\n",
    "X_test['C_RALN'] = X_test['C_RALN'].replace(to_replace = 'U', value = 'normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac90487",
   "metadata": {},
   "source": [
    "```C_TRAF```: Aquí se observa una situación similar a la anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf93692",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview_target(df = XY_train, target = 'C_SEV', obj_val = 'C_TRAF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores Q se engloban dentro de la categoría safe, otro tipo de medida de seguridad no contemplada\n",
    "X_train['C_TRAF'] = X_train['C_TRAF'].replace(to_replace = 'QQ', value = 'safe')\n",
    "X_test['C_TRAF'] = X_test['C_TRAF'].replace(to_replace = 'QQ', value = 'safe')\n",
    "\n",
    "# Valores U se traspasan a la categoría unsafe, misma C_SEV\n",
    "X_train['C_TRAF'] = X_train['C_TRAF'].replace(to_replace = 'UU', value = 'safe')\n",
    "X_test['C_TRAF'] = X_test['C_TRAF'].replace(to_replace = 'UU', value = 'safe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d24797",
   "metadata": {},
   "source": [
    "Verificamos que todo es correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_tools.special_values_summary(df = X_train, vals = especial_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_tools.special_values_summary(df = X_test, vals = especial_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572c202",
   "metadata": {},
   "source": [
    "Hemos tratado todos los valores especiales y ahora nuestro conjunto de datos no posee valores missings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb81e91",
   "metadata": {},
   "source": [
    "### 3.4.3 Codificación de variables y tipos\n",
    "Ahora que hemos tratado los valores missings y especiales procedermos a modificar los tipos y codificaciones de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e658002",
   "metadata": {},
   "source": [
    "#### 3.4.3.1 Variables numéricas\n",
    "Para este modelo consideramos variables numéricas: \n",
    "* ```C_YEAR```: Año del accidente\n",
    "* ```C_VEHS```: Número de vehículos implicados\n",
    "* ```C_PERS```: Número de personas implicadas\n",
    "\n",
    "Solo ```C_PERS``` es ya de tipo numérico. Convertimos las otras dos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c30f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['C_YEAR', 'C_VEHS', 'C_PERS']\n",
    "for col in numeric:\n",
    "    X_train[col] = X_train[col].astype(float)\n",
    "    X_test[col] = X_test[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a0441",
   "metadata": {},
   "source": [
    "#### 3.4.3.2 Variables categóricas: Encoding\n",
    "\n",
    "Vamos a codificar las variable categóricas. Repasemos primero la estructura de las categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5d5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "categorical = ['C_MNTH', 'C_WDAY', 'C_HOUR', 'C_CONF', \n",
    "               'C_RCFG', 'C_WTHR', 'C_RSUR', 'C_RALN', \n",
    "               'C_TRAF']\n",
    "\n",
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 35), sharey=False)\n",
    "fig.suptitle('Categorial Values by Severity (normalized)')\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for cat in categorical:\n",
    "    temp = eda_tools.norm_category(df = XY_train, obj_val = 'C_SEV', cat_val = cat)\n",
    "    sns.barplot(data = temp, x = cat, y = 'group%', hue = 'C_SEV', ax = axes[i,j]);\n",
    "    if (j == 0): \n",
    "        j = 1\n",
    "    else:\n",
    "        j = 0\n",
    "        i += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4ca87",
   "metadata": {},
   "source": [
    "Como norma general debido al elevado uso de categorías en algunas variables, se va a evitar utilizar téncicas como OneHotEncoder de manera abusiva pues crearía demasidas variables.\n",
    "\n",
    "**Label Encoder**\n",
    "\n",
    "Se hará uso del LabelEncoder para las variables con solo dos categorías. Estas son: ```C_RCFG```, ```C_WTHR```, ```C_RSUR```, ```C_RALN``` y ```C_TRAF```. Al tener únicamente dos categorías, resulta interesante hacer uso de 1 y 0 para poder diferenciarlas. \n",
    "\n",
    "Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat = ['C_RCFG', 'C_WTHR', 'C_RSUR', 'C_RALN', 'C_TRAF', 'C_MNTH', 'C_WDAY']\n",
    "lb = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in labelCat:\n",
    "    X_train[cat] = lb.fit_transform(X_train[cat])\n",
    "    X_test[cat] = lb.fit_transform(X_test[cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b71d5",
   "metadata": {},
   "source": [
    "La variable objetivo hay que codificarla también:1 -> 0 y 2 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7210cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de7da9",
   "metadata": {},
   "source": [
    "**One Hot Encoder**\n",
    "\n",
    "Finalmente, haremos uso del OneHotEncoder para la variable ```C_HOUR```. Esta solo tiene tres categorías lo que creará solo dos variables nuevas. \n",
    "\n",
    "Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b19d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "categories = ohe.fit_transform(X_train[['C_HOUR']]).toarray()\n",
    "new_categories = ['C_HOUR_A', 'C_HOUR_M', 'C_HOUR_N']\n",
    "position = 0\n",
    "for nc in new_categories:\n",
    "    accum = list()\n",
    "    for enc in categories:\n",
    "        accum.append(enc[position])\n",
    "    X_train[nc] = accum\n",
    "    position += 1\n",
    "\n",
    "X_train = X_train.drop(['C_HOUR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adca973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "categories = ohe.fit_transform(X_test[['C_HOUR']]).toarray()\n",
    "new_categories = ['C_HOUR_A', 'C_HOUR_M', 'C_HOUR_N']\n",
    "position = 0\n",
    "for nc in new_categories:\n",
    "    accum = list()\n",
    "    for enc in categories:\n",
    "        accum.append(enc[position])\n",
    "    X_test[nc] = accum\n",
    "    position += 1\n",
    "\n",
    "X_test = X_test.drop(['C_HOUR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ffc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "categories = ohe.fit_transform(X_train[['C_CONF']]).toarray()\n",
    "new_categories = ['C_CONF_O', 'C_CONF_TO', 'C_CONF_TS']\n",
    "position = 0\n",
    "for nc in new_categories:\n",
    "    accum = list()\n",
    "    for enc in categories:\n",
    "        accum.append(enc[position])\n",
    "    X_train[nc] = accum\n",
    "    position += 1\n",
    "\n",
    "X_train = X_train.drop(['C_CONF'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942faeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "categories = ohe.fit_transform(X_test[['C_CONF']]).toarray()\n",
    "new_categories = ['C_CONF_O', 'C_CONF_TO', 'C_CONF_TS']\n",
    "position = 0\n",
    "for nc in new_categories:\n",
    "    accum = list()\n",
    "    for enc in categories:\n",
    "        accum.append(enc[position])\n",
    "    X_test[nc] = accum\n",
    "    position += 1\n",
    "\n",
    "X_test = X_test.drop(['C_CONF'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3449c",
   "metadata": {},
   "source": [
    "## 3.5 Escalado\n",
    "Realizamos un escalado de las variables del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test= pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05584571",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3e7ccb",
   "metadata": {},
   "source": [
    "## 3.6 Balanceo\n",
    "En el EDA pudimos apreciar como había un importante desequilibrio en la variable objetivo, existiendo un 98% y 2% de accidentes no mortales y mortales respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da204234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sev = X_train\n",
    "X_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview(df = X_train_sev, obj_val = 'C_SEV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723ffd2",
   "metadata": {},
   "source": [
    "Hacemos uso de la técnica de balanceo Smote Tomek Links con un remuestreo de a clase mayoritaria (accidentes no mortales) de tal forma que los datos estén más equilibrado y permitan al modelo un mejor aprendizaje de ambas clases.\n",
    "\n",
    "Ref: https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc\n",
    "\n",
    "Ref: https://imbalanced-learn.org/dev/references/generated/imblearn.under_sampling.TomekLinks.html#imblearn.under_sampling.TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aabdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797d272",
   "metadata": {},
   "source": [
    "Observamos como se ha reducido considerablemente la muestra de accidentes no mortales, y hemos podido equilibrar en cierto grado el dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sev = X_train\n",
    "X_train['C_SEV'] = Y_train\n",
    "eda_tools.classes_overview(df = X_train_sev, obj_val = 'C_SEV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26836cbf",
   "metadata": {},
   "source": [
    "## 3.7 Selección de variables\n",
    "\n",
    "### 3.7.1 Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "sns.heatmap(XY_train[['C_SEV', 'C_YEAR', 'C_VEHS', 'C_PERS']].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76d479",
   "metadata": {},
   "source": [
    "Analizamos las correlaciones de las variables continuas del modelo. Observamos como no existe una fuerte correlación con la variable objetivo, si bien las variables ```C_VEHS``` y ```C_PERS``` muestran un correlación a destacar. Esta es normal teniendo en cuenta que el número de vehículos involucrados tienen una relación con las personas involucradas al ser estas usuarios de estos vehículos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd099c",
   "metadata": {},
   "source": [
    "### 3.7.2 Regresión de Lasso\n",
    "A continuación procedemos a realizar una regresión de Lasso con el objetivo de valorar que variables del modelo son mayormente significativas e importantes para el mismo. De esta forma reducimos las variables y simplificamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sel_lasso = SelectFromModel(LogisticRegression(C=1, penalty='l1', \n",
    "                                          solver='liblinear'), threshold = 0.1) # jugar con el threshold\n",
    "sel_lasso.fit(X_train, Y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sel_lasso.get_support()\n",
    "selected_feat_lasso = X_train.columns[sel_lasso.get_support()]\n",
    "selected_feat_lasso\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''categorical = selected_feat_lasso\n",
    "\n",
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "\n",
    "fig, axes = plt.subplots(7, 2, figsize=(15, 35), sharey=False)\n",
    "fig.suptitle('Categorial Values by Severity (normalized)')\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for cat in categorical:\n",
    "    temp = eda_tools.norm_category(df = XY_train, obj_val = 'C_SEV', cat_val = cat)\n",
    "    sns.barplot(data = temp, x = cat, y = 'group%', hue = 'C_SEV', ax = axes[i,j]);\n",
    "    if (j == 0): \n",
    "        j = 1\n",
    "    else:\n",
    "        j = 0\n",
    "        i += 1\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Coeficientes del modelo\n",
    "# ==============================================================================\n",
    "df_coeficientes_lasso = pd.DataFrame(\n",
    "                        {'predictor': X_train.columns,\n",
    "                         'coef': sel_lasso.estimator_.coef_.flatten()}\n",
    "                  )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 3.84))\n",
    "ax.stem(df_coeficientes_lasso.predictor, df_coeficientes_lasso.coef, markerfmt=' ')\n",
    "plt.xticks(rotation=90, ha='right', size=10)\n",
    "ax.set_xlabel('variable')\n",
    "ax.set_ylabel('coeficientes')\n",
    "ax.set_title('Coeficientes del modelo lasso');\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56406ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar solo si hacemos uso de Lasso\n",
    "#X_train = X_train[selected_feat_lasso]\n",
    "#X_test = X_test[selected_feat_lasso]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c77d6",
   "metadata": {},
   "source": [
    "## 3.8 Modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d45c9",
   "metadata": {},
   "source": [
    "Finalmente, ya tenemos dos conjuntos procesados de train y test que podemos utilizar para realizar los modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d5053",
   "metadata": {},
   "source": [
    "### 3.8.1 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e18ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de train\n",
    "XY_train = X_train.copy()\n",
    "XY_train['C_SEV'] = Y_train\n",
    "\n",
    "# Revisar nombres antes de guardar (CUIDADO: Sobreescritura)\n",
    "# Crear nueva carpeta <model_x> si es nuevo\n",
    "XY_train.to_csv(\"../data/csev/model_5/fulltrainCSEV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b55aea",
   "metadata": {},
   "source": [
    "### 3.8.2 Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de test\n",
    "XY_test = X_test.copy()\n",
    "XY_test['C_SEV'] = Y_test\n",
    "\n",
    "# Revisar nombres antes de guardar (CUIDADO: Sobreescritura)\n",
    "# Crear nueva carpeta <model_x> si es nuevo\n",
    "XY_test.to_csv(\"../data/csev/model_5/fulltestCSEV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae79e60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37753630",
   "metadata": {},
   "source": [
    "<div style='text-align:center'>Elaborado por Álvaro Serrano del Rincón (<i>a.serranodelrincon@cunef.edu</i>)</div> \n",
    "<div style='text-align:center'>y Carlos Viñals Guitart (<i>carlos.vinals@cunef.edu</i>)</div> "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "894f340193c41f12f2ad2c5acdc4753fc38d435e21d2507739dfff3cc0eea455"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ML_P1]",
   "language": "python",
   "name": "conda-env-ML_P1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
